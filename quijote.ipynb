{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX8gZlVyCCbz"
   },
   "source": [
    "# Laboratorio: Modelos del lenguaje con RNNs\n",
    "\n",
    "En este laboratorio, vamos a entrenar un modelo del lenguaje basado en caracteres con Recurrent Neural Networks. Asimismo, utilizaremos el modelo para generar texto. En particular, alimentaremos nuestro modelo con obras de la literatura clásica en castellano para obtener una red neuronal que sea capaz de \"escribir\" fragmentos literarios.\n",
    "\n",
    "Los entrenamientos en esta laboratorio para obtener un modelo de calidad podrían tomar cierto tiempo (5-10 minutos por epoch), por lo que se aconseja empezar a trabajar pronto. El uso de GPUs no ayuda tanto con LSTMs como con CNNs, por lo que si tenéis máquinas potentes en casa es posible que podáis entrenar más rápido o a la misma velocidad que en Colab. En todo caso, la potencia de Colab es más que suficiente para completar este laboratorio con éxito.\n",
    "\n",
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/d/d8/El_ingenioso_hidalgo_don_Quijote_de_la_Mancha.jpg\" style=\"text-align: center\" height=\"300px\"></center>\n",
    "\n",
    "El dataset a utilizar consistirá en un archivo de texto con el contenido íntegro en castellano antiguo de El Ingenioso Hidalgo Don Quijote de la Mancha, disponible de manera libre en la página de [Project Gutenberg](https://www.gutenberg.org). Asimismo, como apartado optativo en este laboratorio se pueden utilizar otras fuentes de texto. Aquí podéis descargar los datos a utilizar de El Quijote y un par de obras adicionales:\n",
    "\n",
    "[El ingenioso hidalgo Don Quijote de la Mancha (Miguel de Cervantes)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io)\n",
    "\n",
    "[Compilación de obras teatrales (Calderón de la Barca)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219433&authkey=AKvGD6DC3IRBqmc)\n",
    "\n",
    "[Trafalgar (Benito Pérez Galdós)](https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219434&authkey=AErPCAtMKOI5tYQ)\n",
    "\n",
    "Como ya deberíamos de estar acostumbrados en problemas de Machine Learning, es importante echar un vistazo a los datos antes de empezar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QI274F8LQC59"
   },
   "source": [
    "## 1. Carga y procesado del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZNnzvXuqVVm"
   },
   "source": [
    "Primero, vamos a descargar el libro e inspeccionar los datos. El fichero a descargar es una versión en .txt del libro de Don Quijote, a la cual se le han borrado introducciones, licencias y otras secciones para dejarlo con el contenido real de la novela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "D7tKOZ9BFfki"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import random\n",
    "import io\n",
    "\n",
    "path = keras.utils.get_file(\n",
    "    fname=\"don_quijote.txt\", \n",
    "    origin=\"https://onedrive.live.com/download?cid=C506CF0A4F373B0F&resid=C506CF0A4F373B0F%219424&authkey=AH0gb-qSo5Xd7Io\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VYGLvjLXrUUd"
   },
   "source": [
    "Una vez descargado, vamos a leer el contenido del fichero en una variable. Adicionalmente, convertiremos el contenido del texto a minúsculas para ponérselo un poco más fácil a nuestro modelo (de modo que todas las letras sean minúsculas y el modelo no necesite diferenciar entre minúsculas y mayúsculas).\n",
    "\n",
    "**1.1.** Leer todo el contenido del fichero en una única variable ***text*** y convertir el string a minúsculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "8WB6FejrrTu9"
   },
   "outputs": [],
   "source": [
    "## TU CÓDIGO AQUÍ\n",
    "text=open(path,encoding=\"utf-8\").read().lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkgGl8GWtUk8"
   },
   "source": [
    "Podemos comprobar ahora que efectivamente nuestra variable contiene el resultado deseado, con el comienzo tan característico del Quijote."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hMFhe3COFwSD",
    "outputId": "67efcf1b-6062-4ed0-eafd-6e0bb859ec1c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud del texto: 2071198\n",
      "capítulo primero. que trata de la condición y ejercicio del famoso hidalgo\n",
      "don quijote de la mancha\n",
      "\n",
      "\n",
      "en un lugar de la mancha, de cuyo nombre no quiero acordarme, no ha mucho\n",
      "tiempo que vivía un hidalgo de los de lanza en astillero, adarga antigua,\n",
      "rocín flaco y galgo corredor. una olla de algo más\n"
     ]
    }
   ],
   "source": [
    "print(\"Longitud del texto: {}\".format(len(text)))\n",
    "print(text[0:300])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos caracteres especiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "JkBuc5JbP6Fn"
   },
   "outputs": [],
   "source": [
    "texto=\"\"\n",
    "for letra in text:\n",
    "  if not letra in \"?¿.,'¡!()-_{}\\\"[]«»:;\\n\":\n",
    "    texto+=letra\n",
    "text=texto"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Creamos un diccionario con las letras diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7RTFZikNb4-",
    "outputId": "8e77a1a9-bc40-487d-8329-7a4b0fd7f9d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': 0,\n",
       " 'j': 1,\n",
       " '3': 2,\n",
       " 'á': 3,\n",
       " 'o': 4,\n",
       " 'í': 5,\n",
       " ' ': 6,\n",
       " 'ï': 7,\n",
       " 'ù': 8,\n",
       " 'y': 9,\n",
       " 'g': 10,\n",
       " 'm': 11,\n",
       " 'i': 12,\n",
       " 'e': 13,\n",
       " '0': 14,\n",
       " 'ú': 15,\n",
       " '4': 16,\n",
       " 'ó': 17,\n",
       " 'q': 18,\n",
       " 'f': 19,\n",
       " 'u': 20,\n",
       " 'ñ': 21,\n",
       " 'w': 22,\n",
       " 'h': 23,\n",
       " 't': 24,\n",
       " 'a': 25,\n",
       " '2': 26,\n",
       " 'n': 27,\n",
       " '7': 28,\n",
       " 'r': 29,\n",
       " 'x': 30,\n",
       " 'ü': 31,\n",
       " 'c': 32,\n",
       " 'v': 33,\n",
       " 'z': 34,\n",
       " 'à': 35,\n",
       " '1': 36,\n",
       " 'é': 37,\n",
       " '6': 38,\n",
       " 'd': 39,\n",
       " 'b': 40,\n",
       " 's': 41,\n",
       " '5': 42,\n",
       " 'l': 43}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letras = texto\n",
    "letras_unicas = set(letras)\n",
    "word_index = {}\n",
    "k=0\n",
    "for letra in letras_unicas:\n",
    "    word_index[letra] = k\n",
    "    k+=1\n",
    "word_index # muestra el diccionario "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(letras_unicas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AQ9lfMpmY61N"
   },
   "outputs": [],
   "source": [
    "# Perform reverse word lookup \n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y_B4AWo0ElwA"
   },
   "source": [
    "####  Obtención de secuencias de entrada y palabra a predecir\n",
    "\n",
    "Ahora, vamos a obtener las secuencias de entrada en formato texto y los correspondientes palabras a predecir. Para ello, recorrer el texto completo leído anteriormente, obteniendo una secuencia de SEQ_LENGTH palabras y la siguiente a predecir. Una vez hecho, desplazarse una palabra a la izquierda y hacer lo mismo para obtener una nueva secuencia y predicción. Guardar las secuencias en una variable ***sequences*** y los caracteres a predecir en una variable ***next_words***.\n",
    "\n",
    "Por ejemplo, si el texto fuera \"Don Quijote de La Mancha\" y SEQ_LENGTH fuese 5, tendríamos\n",
    "\n",
    "* *sequences* = [\"Don Quijote de La Mancha\", \"Quijote de La Mancha de\", \"de La Mancha de cuyo\", \"La Mancha de cuyo nombre\", \"Mancha de cuyo nombre no\", \"de cuyo nombre no quiero\"]\n",
    "* *next_words* = ['de', 'cuyo', 'nombre', 'no', 'quiero', 'acordarme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NslxhnnDK6uA"
   },
   "outputs": [],
   "source": [
    "# Definimos el tamaño de las secuencias. Puedes dejar este valor por defecto.\n",
    "SEQ_LENGTH = 10\n",
    "step=1 # Para que la siguiente sentencia esté desplazada una palabra la izquierda.\n",
    "sequences = []\n",
    "next_words = []\n",
    "\n",
    "## TU CÓDIGO AQUÍ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Y3AmjYtHdLJ"
   },
   "source": [
    "Indicar el tamaño del training set que acabamos de generar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WVWqKxFcbwTu"
   },
   "outputs": [],
   "source": [
    "## TU CÓDIGO AQUÍ\n",
    "for i in range(0,len(letras)-SEQ_LENGTH, step):\n",
    "  sequences.append(letras[i:i+SEQ_LENGTH])\n",
    "  next_words.append(letras[i+SEQ_LENGTH])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "8_0VLaLZg0og",
    "outputId": "2fba25d4-63f2-498c-ac4c-84e811e788c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'que trata '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "1zbXlIwHg5VR",
    "outputId": "bf52ed1e-0d23-4c5a-cf68-c454e0e033d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "goGQkKcwpLRJ"
   },
   "source": [
    "Como el Quijote es muy largo y tenemos muchas secuencias, podríamos encontrar problemas de memoria. Por ello, vamos a elegir un número máximo de ellas. Si estás corriendo esto localmente y tienes problemas de memoria, puedes reducir el tamaño aún más, pero ten cuidado porque, a menos datos, peor calidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2pm1Q19ppw8F",
    "outputId": "071240ed-ae5a-41c9-aff1-5df60e59f20a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1968243\n"
     ]
    }
   ],
   "source": [
    "MAX_SEQUENCES = len(sequences)\n",
    "\n",
    "sequences, next_words = np.array(sequences), np.array(next_words)\n",
    "sequences, next_words = list(sequences[:MAX_SEQUENCES]), list(next_words[:MAX_SEQUENCES])\n",
    "\n",
    "print(len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VlWnHUZW8jGP",
    "outputId": "398a9a47-fe08-4af8-d61e-15de7ed85f47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'de la cond'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "YbGeN3crm8Sj",
    "outputId": "3e2affe4-e76e-4ec3-f0cd-5362a0617c0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_words[27]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "GydwmFa85Qur"
   },
   "source": [
    "# Obtención de input X y output y para el modelo\n",
    "\n",
    "Finalmente, a partir de los datos de entrenamiento que hemos generado vamos a crear los arrays de datos X e y que pasaremos a nuestro modelo.\n",
    "\n",
    "Para ello, vamos a utilizar one-hot encoding para nuestras palabras. Por ejemplo, si tuviéramos 4 letras las representaciones serían: (1, 0, 0, 0), (0, 1, 0, 0), (0, 0, 1, 0) y (0, 0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "SF10kwxL4jVm"
   },
   "outputs": [],
   "source": [
    "NUM_SEQUENCES = len(sequences)\n",
    "X = np.zeros((NUM_SEQUENCES, SEQ_LENGTH, 44))\n",
    "y = np.zeros((NUM_SEQUENCES, 44))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(NUM_SEQUENCES):\n",
    "  for k,j in enumerate(sequences[i]):\n",
    "    X[i][k][word_index[j]]=1\n",
    "    \n",
    "    \n",
    "for k in range(NUM_SEQUENCES):\n",
    "  y[k][word_index[next_words[k]]] = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Definición del modelo y entrenamiento\n",
    "Una vez tenemos ya todo preparado, es hora de definir el modelo. Define un modelo que utilice una LSTM con 128 unidades internas. Si bien el modelo puede definirse de una manera más compleja, para empezar debería bastar con una LSTM más una capa Dense con el softmax que predice el siguiente caracter a producir. Adam puede ser una buena elección de optimizador.\n",
    "\n",
    "Una vez el modelo esté definido, entrénalo un poco para asegurarte de que la loss es decreciente. No es necesario guardar la salida de este entrenamiento en el entregable final, ya que vamos a hacer el entrenamiento más informativo en el siguiente punto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UVI7hYdY7Lkg",
    "outputId": "fa2f2000-a153-4471-cba6-58b80d3a4077"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 10, 128)           88576     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              132096    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 44)                45100     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 397,356\n",
      "Trainable params: 397,356\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## TU CÓDIGO AQUÍ\n",
    "vocabulary_size=len(letras_unicas)\n",
    "model=Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQ_LENGTH,44), return_sequences=True))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(1024,activation='relu'))\n",
    "model.add(Dense(44,activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "MEOYzP5v-exO"
   },
   "outputs": [],
   "source": [
    "optimizer='adam'\n",
    "model.compile(loss='categorical_crossentropy',optimizer=optimizer,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "fhp02KFy-mRk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7305/7305 [==============================] - 474s 64ms/step - loss: 1.6741 - accuracy: 0.4828 - val_loss: 1.4447 - val_accuracy: 0.5534\n",
      "Epoch 2/20\n",
      "7305/7305 [==============================] - 481s 66ms/step - loss: 1.3724 - accuracy: 0.5717 - val_loss: 1.3654 - val_accuracy: 0.5763\n",
      "Epoch 3/20\n",
      "7305/7305 [==============================] - 484s 66ms/step - loss: 1.3089 - accuracy: 0.5892 - val_loss: 1.3324 - val_accuracy: 0.5870\n",
      "Epoch 4/20\n",
      "7305/7305 [==============================] - 475s 65ms/step - loss: 1.2736 - accuracy: 0.5992 - val_loss: 1.3119 - val_accuracy: 0.5919\n",
      "Epoch 5/20\n",
      "7305/7305 [==============================] - 471s 65ms/step - loss: 1.2492 - accuracy: 0.6057 - val_loss: 1.3044 - val_accuracy: 0.5961\n",
      "Epoch 6/20\n",
      "7305/7305 [==============================] - 467s 64ms/step - loss: 1.2311 - accuracy: 0.6110 - val_loss: 1.2928 - val_accuracy: 0.5986\n",
      "Epoch 7/20\n",
      "7305/7305 [==============================] - 474s 65ms/step - loss: 1.2162 - accuracy: 0.6149 - val_loss: 1.2897 - val_accuracy: 0.6011\n",
      "Epoch 8/20\n",
      "7305/7305 [==============================] - 479s 66ms/step - loss: 1.2036 - accuracy: 0.6183 - val_loss: 1.2855 - val_accuracy: 0.6034\n",
      "Epoch 9/20\n",
      "7305/7305 [==============================] - 473s 65ms/step - loss: 1.1925 - accuracy: 0.6214 - val_loss: 1.2807 - val_accuracy: 0.6057\n",
      "Epoch 10/20\n",
      "7305/7305 [==============================] - 477s 65ms/step - loss: 1.1826 - accuracy: 0.6240 - val_loss: 1.2808 - val_accuracy: 0.6058\n",
      "Epoch 11/20\n",
      "7305/7305 [==============================] - 473s 65ms/step - loss: 1.1743 - accuracy: 0.6268 - val_loss: 1.2826 - val_accuracy: 0.6052\n",
      "Epoch 12/20\n",
      "7305/7305 [==============================] - 471s 65ms/step - loss: 1.1666 - accuracy: 0.6284 - val_loss: 1.2883 - val_accuracy: 0.6054\n",
      "Epoch 13/20\n",
      "7305/7305 [==============================] - 471s 64ms/step - loss: 1.1593 - accuracy: 0.6310 - val_loss: 1.2849 - val_accuracy: 0.6069\n",
      "Epoch 14/20\n",
      "7305/7305 [==============================] - 469s 64ms/step - loss: 1.1525 - accuracy: 0.6327 - val_loss: 1.2841 - val_accuracy: 0.6049\n",
      "Epoch 15/20\n",
      "7305/7305 [==============================] - 469s 64ms/step - loss: 1.1465 - accuracy: 0.6342 - val_loss: 1.2852 - val_accuracy: 0.6064\n",
      "Epoch 16/20\n",
      "7305/7305 [==============================] - 468s 64ms/step - loss: 1.1408 - accuracy: 0.6359 - val_loss: 1.2931 - val_accuracy: 0.6078\n",
      "Epoch 17/20\n",
      "7305/7305 [==============================] - 470s 64ms/step - loss: 1.1355 - accuracy: 0.6373 - val_loss: 1.2928 - val_accuracy: 0.6070\n",
      "Epoch 18/20\n",
      "7305/7305 [==============================] - 485s 66ms/step - loss: 1.1309 - accuracy: 0.6388 - val_loss: 1.2893 - val_accuracy: 0.6088\n",
      "Epoch 19/20\n",
      "7305/7305 [==============================] - 485s 66ms/step - loss: 1.1261 - accuracy: 0.6401 - val_loss: 1.3000 - val_accuracy: 0.6074\n",
      "Epoch 20/20\n",
      "7305/7305 [==============================] - 473s 65ms/step - loss: 1.1217 - accuracy: 0.6413 - val_loss: 1.3019 - val_accuracy: 0.6074\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(X,y, validation_split=0.05, batch_size=256, epochs=20,shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_LSTM.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib # Para salvar el modelo\n",
    "joblib.dump(model,'modelo_LSTM.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----FALSE-----\n",
      "Letra predicha: \"i\"\n",
      "Letra: r\n",
      "-----TRUE-----\n",
      "Letra predicha: \"i\"\n",
      "Letra: i\n",
      "-----TRUE-----\n",
      "Letra predicha: \"m\"\n",
      "Letra: m\n",
      "-----TRUE-----\n",
      "Letra predicha: \"e\"\n",
      "Letra: e\n",
      "-----TRUE-----\n",
      "Letra predicha: \"r\"\n",
      "Letra: r\n",
      "-----TRUE-----\n",
      "Letra predicha: \"o\"\n",
      "Letra: o\n",
      "-----TRUE-----\n",
      "Letra predicha: \" \"\n",
      "Letra:  \n",
      "-----TRUE-----\n",
      "Letra predicha: \"q\"\n",
      "Letra: q\n",
      "-----TRUE-----\n",
      "Letra predicha: \"u\"\n",
      "Letra: u\n",
      "-----TRUE-----\n",
      "Letra predicha: \"e\"\n",
      "Letra: e\n",
      "-----TRUE-----\n",
      "Letra predicha: \" \"\n",
      "Letra:  \n",
      "-----FALSE-----\n",
      "Letra predicha: \"e\"\n",
      "Letra: t\n",
      "-----FALSE-----\n",
      "Letra predicha: \"e\"\n",
      "Letra: r\n",
      "-----TRUE-----\n",
      "Letra predicha: \"a\"\n",
      "Letra: a\n",
      "-----TRUE-----\n",
      "Letra predicha: \"t\"\n",
      "Letra: t\n",
      "-----TRUE-----\n",
      "Letra predicha: \"a\"\n",
      "Letra: a\n",
      "-----TRUE-----\n",
      "Letra predicha: \" \"\n",
      "Letra:  \n",
      "-----TRUE-----\n",
      "Letra predicha: \"d\"\n",
      "Letra: d\n",
      "-----TRUE-----\n",
      "Letra predicha: \"e\"\n",
      "Letra: e\n",
      "-----TRUE-----\n",
      "Letra predicha: \" \"\n",
      "Letra:  \n",
      "Aciertos 17/20\n"
     ]
    }
   ],
   "source": [
    "a = 0\n",
    "cont = 20\n",
    "\n",
    "for i in range(cont):\n",
    "    X_pred = np.zeros((1, SEQ_LENGTH, 44))\n",
    "    for j, k in enumerate(X[i]):\n",
    "        X_pred[0,j] = k\n",
    "    pred = model.predict(X_pred, batch_size = 32, verbose = 0)\n",
    "    if (reverse_word_index[np.argmax(pred)] == reverse_word_index[np.argmax(y[i])]):\n",
    "        print('-----TRUE-----')\n",
    "        a+=1\n",
    "    else:\n",
    "        print('-----FALSE-----')\n",
    "    print(f'Letra predicha: \\\"{reverse_word_index[np.argmax(pred)]}\\\"')\n",
    "    print(f'Letra: {reverse_word_index[np.argmax(y[i])]}')\n",
    "\n",
    "\n",
    "print(f'Aciertos {a}/{cont}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción para una frase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capítulo p\n",
      "capítulo pi que estaba de la caballería \n"
     ]
    }
   ],
   "source": [
    "X_pred = np.zeros((1, SEQ_LENGTH, vocabulary_size))\n",
    "final = ''.join(sequences[0])\n",
    "print(final)\n",
    "\n",
    "for i, j in enumerate(X[0]):\n",
    "    X_pred[0,i]=j\n",
    "\n",
    "for i in range(30):\n",
    "    newLeter = np.zeros(vocabulary_size)\n",
    "    prediccion = model.predict(X_pred, batch_size=32, verbose=0)\n",
    "    X_pred = np.delete(X_pred, 0,1)\n",
    "    newLeter[np.argmax(prediccion)] = 1\n",
    "    X_pred = np.append(X_pred, [[newLeter]] , axis=1)\n",
    "    final += reverse_word_index[np.argmax(prediccion)]\n",
    "    \n",
    "print(final)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
